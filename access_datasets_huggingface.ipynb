{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/lsKdhBqoI4Kh7a3/KgZK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DivyaSwamy/Channel-Dynamics/blob/master/access_datasets_huggingface.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ***Author - Divya Swaminathan***\n",
        "##### ***Date - August 2025***\n",
        "---\n",
        "\n",
        "### **Goals** -\n",
        "> In this tutorial we will load vision datasets from huggingface and explore them.\n",
        "\n",
        "**Step1**  - Generate a token by logging into Hugging face (optional but recommended)\n",
        "  * Login to HF,\n",
        "  * Navigate to access tokens, generate token for google colab,\n",
        "  * On your google colab notebook open secrets key on the left panel and paste copied token.\n",
        "\n",
        "**Step2** -\n",
        "  * We will load & explore a dataset in the process learning the how datasets works within huggingface.\n",
        "    * Navigate to the huggingface portal, search for relevant datasets and copy path to dataset. One can use this to access the dataset from huggingface.\n",
        "    * I have chosen \"Aliounethegoat/classification-medicale-multi-cancer\" for this tutorial\n",
        "    \n",
        "**Step3**\n",
        "  * Excercise - load and explore an EHR dataset\n",
        "  * \"QuirkyDataScientist/synthetic_ehr_dataset_part_5\"\n"
      ],
      "metadata": {
        "id": "XcbPkPqgEwaI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Install transformers and datasets"
      ],
      "metadata": {
        "id": "qJVez8xaUXGs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aB3GU6fkEsNm"
      },
      "outputs": [],
      "source": [
        "%pip install -q transformers\n",
        "%pip install -U datasets[vision]\n",
        "\n",
        "# use %pip install -U datasets to access all datasets in Huggingface.\n",
        "# datasets[vision] -one is only accessing vision datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> The following bit of code checks for the huggingface token.\n",
        "\n",
        "In my notebook, under settings, the token is saved under the name 'huggingface_token'.\n",
        "If this name is changed, correspondingly the ***userdata.get(name)*** will change."
      ],
      "metadata": {
        "id": "zI-Yt1SbWE9G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "\n",
        "HF_TOKEN = userdata.get('huggingface_token') # Retrieve the token from secrets\n",
        "\n",
        "if HF_TOKEN:\n",
        "  login(HF_TOKEN)\n",
        "  print(\"Successfully logged in to Hugging Face!\")\n",
        "else:\n",
        "  print(\"Hugging Face token not found in Colab Secrets.\")\n"
      ],
      "metadata": {
        "id": "_YkSWokzwPOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset_builder, load_dataset\n",
        "from datasets import  get_dataset_split_names, DatasetDict, Dataset"
      ],
      "metadata": {
        "id": "xwSb5iwHE5Nw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "* One can navigate to the huggingface portal, search for relevant datasets and copy path to dataset. One can use this to access the dataset from huggingface.\n",
        "\n",
        "* *`load_dataset_builder(path_to_dataset)`* - use function to load a dataset builder and inspect a datasetâ€™s attributes without committing to downloading it:\n",
        "\n",
        "* For every dataset you can check it's *info* (description of dataset) and *features* (what's in it, images, labels etc.) and *splits* (train, test, validate) fields.\n"
      ],
      "metadata": {
        "id": "YJvZmaC4V7YF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_dataset = \"Aliounethegoat/classification-medicale-multi-cancer\"\n",
        "#path_to_dataset = \"cornell-movie-review-data/rotten_tomatoes\"\n",
        "\n",
        "ds_builder = load_dataset_builder(path_to_dataset)"
      ],
      "metadata": {
        "id": "p0P_zeiqE90g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* *`ds_builder = load_dataset_builder(path_to_dataset)`* , here you will get a warning if you are logged out of your hugging face account. Once logged in the warning disappears.\n",
        "\n",
        "\n",
        "* If you are happy with the dataset use function *`load_dataset()`* to download dataset.\n"
      ],
      "metadata": {
        "id": "lh0fqwD9YsYX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for ds_builder there are 2 main features - description and features.\n",
        "\n",
        "print(ds_builder.info.description)\n",
        "print('-------')\n",
        "print(ds_builder.info.features)\n",
        "print('-------')\n",
        "print(ds_builder.info.splits)\n"
      ],
      "metadata": {
        "id": "6VNjuSDAFns9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for elem in ds_builder.info.features:\n",
        "  print(elem, ':-',ds_builder.info.features[elem] )"
      ],
      "metadata": {
        "id": "tdP0GXElXBTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "dataset = load_dataset(path_to_dataset)\n",
        "print('---------')\n",
        "dataset"
      ],
      "metadata": {
        "id": "76Y_L13rF726"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Only training set with 130002 images.\n",
        "# Each image has a label & label_name associated with it.\n",
        "dataset"
      ],
      "metadata": {
        "id": "1OPzyGwlb5K_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If the DatasetDict is such that it has train, test and validate datasets here\n",
        "# the output of this command would be a list stating the same.\n",
        "get_dataset_split_names(path_to_dataset)"
      ],
      "metadata": {
        "id": "tXCO5TL9M_GA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print( dataset['train'][0])\n",
        "print(dataset['train'][1500])\n",
        "print(dataset['train'][13000])"
      ],
      "metadata": {
        "id": "ses6BhVOetjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "* What is the difference b/w label and label_name?\n",
        "\n",
        "The dataset has images from various cancer types. Label_names labels cancer type. Label is the sub classification for a cancer type. Without a datadict, it's unclear what each sub classification refers to"
      ],
      "metadata": {
        "id": "Rf2H1QEDR9jW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "count_label_names = defaultdict(int)\n",
        "count_label = defaultdict(int)\n",
        "\n",
        "for item in dataset['train']['label']:\n",
        "  count_label[item]+= 1\n",
        "\n",
        "for item in dataset['train']['label_name']:\n",
        "  count_label_names[item]+= 1\n"
      ],
      "metadata": {
        "id": "ZxsAixj4WmRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_label"
      ],
      "metadata": {
        "id": "wnpEevudgbF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_label_names"
      ],
      "metadata": {
        "id": "J-RvYgwsgfHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Can you isolate all the breast cancer images !!\n",
        "\n",
        "Yes.\n",
        "\n",
        "* dataset['train'][25000:35000] is also viable though slow.\n"
      ],
      "metadata": {
        "id": "qv5sW1v2hF22"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This logic runs very slowly\n",
        "breast_cancer = dataset['train'].filter(lambda x: x['label_name'] == 'cancer_sein')\n"
      ],
      "metadata": {
        "id": "MZRE3MsjSfRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "breast_cancer"
      ],
      "metadata": {
        "id": "5JYMisQzir-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(breast_cancer[500])\n",
        "print(breast_cancer[-500])"
      ],
      "metadata": {
        "id": "PDg84tbelOnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#next(iter(vision_dataset['train']))"
      ],
      "metadata": {
        "id": "twzrE0FwiXd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Let's plot a random section of images from breast_cancer dataset"
      ],
      "metadata": {
        "id": "p6nLpzEil9bz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "tl23-6Efk3be"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = [random.randint(0, 10000) for i in range(10)]\n",
        "\n",
        "fig, axs = plt.subplots(2,5, figsize = (10,5))\n",
        "axs = axs.ravel()\n",
        "\n",
        "for i in range(10):\n",
        "  j = idx[i]\n",
        "  image_np = np.array(breast_cancer[j]['image'])\n",
        "  pil_image = Image.fromarray(image_np)\n",
        "  # print('Image Dimensions', image_np.shape, pil_image.size)\n",
        "  axs[i].imshow(image_np)\n",
        "  axs[i].set_title(breast_cancer[j]['label_name'] +': '\n",
        "         + breast_cancer[j]['label'], fontsize = 6)\n",
        "  axs[i].set_axis_off()\n"
      ],
      "metadata": {
        "id": "ra3t_XfamhMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Is it a balanced dataset?\n",
        "\n",
        "count_label = defaultdict(int)\n",
        "\n",
        "for item in breast_cancer['label']:\n",
        "  count_label[item]+= 1\n",
        "\n",
        "print(count_label)"
      ],
      "metadata": {
        "id": "I1kOO540nhvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Using iterable datasets -> convert dataset on to iteratable dataset and explore\n",
        "\n",
        " *` There are two types of dataset objects, a Dataset and an IterableDataset. Whichever type of dataset you choose to use or create depends on the size of the dataset. In general, an IterableDataset is ideal for big datasets (think hundreds of GBs!) due to its lazy behavior and speed advantages, while a Dataset is great for everything else. This page will compare the differences between a Dataset and an IterableDataset to help you pick the right dataset object for you.`*\n",
        "\n",
        " > Since breast_cancer is a subset of ds, it wasn't necessary to use iterable_dataset here. Neverthless good for practise."
      ],
      "metadata": {
        "id": "2A_FebMsuetg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iterable_bc = breast_cancer.to_iterable_dataset()"
      ],
      "metadata": {
        "id": "03UskcLMk_Tv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = next(iter(breast_cancer.shuffle())) # try this what happens if you use x = next(iter(breast_cancer))\n",
        "\n",
        "image_np = np.array(x['image'])\n",
        "pil_image = Image.fromarray(image_np)\n",
        "plt.imshow(pil_image)\n",
        "plt.title(x['label'])\n",
        "\n"
      ],
      "metadata": {
        "id": "8wT6Xw0suyMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For an iterable dataset, use .shuffle() to shuffle images.\n",
        "  * .take() can be used to extract a specific image id.\n",
        "  * using list with .take() will list the number of images specified within .take(). The larger this number the longer it takes for the program to list all images.\n",
        "\n"
      ],
      "metadata": {
        "id": "tmgTFyVr6ebh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "list(breast_cancer.shuffle().take(5))\n"
      ],
      "metadata": {
        "id": "l8EIV60ElB3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using .take you are accessing a single image from the dataset.\n",
        "breast_cancer.take(1000)"
      ],
      "metadata": {
        "id": "w3XfaoorjrA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    from ipywidgets import Widget\n",
        "    Widget.close_all()"
      ],
      "metadata": {
        "id": "ib3EZ6bXR-iL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3xegGc5yR_Bu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}